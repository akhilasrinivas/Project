from tensorflow import keras
import pandas as pd
from sklearn.model_selection import train_test_split

# Load and Preprocess the Dataset
data = pd.read_csv("C:\\Users\\ssred\\OneDrive\\Desktop\\Core-Project\\strength10.csv")  # Replace with your dataset path
data.dropna(subset=["password", "strength"], inplace=True)

X = data["password"]
y = data["strength"]

# Split the Data into Training and Testing Sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Build and Train the ANN Model
model = keras.Sequential()
model.add(keras.layers.Embedding(input_dim=256, output_dim=32, input_length=20))
model.add(keras.layers.Flatten())  # Replace Conv1D and GlobalMaxPooling1D with Flatten
model.add(keras.layers.Dense(128, activation='relu'))  # You can adjust the number of neurons
model.add(keras.layers.Dense(3, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Tokenize and pad the data for the ANN model
tokenizer = keras.preprocessing.text.Tokenizer(char_level=True, filters=None)
tokenizer.fit_on_texts(X_train)
X_train_ANN = tokenizer.texts_to_sequences(X_train)
X_test_ANN = tokenizer.texts_to_sequences(X_test)
X_train_ANN = keras.preprocessing.sequence.pad_sequences(X_train_ANN, maxlen=20)
X_test_ANN = keras.preprocessing.sequence.pad_sequences(X_test_ANN, maxlen=20)

model.fit(X_train_ANN, y_train,epochs=30, batch_size=64, validation_data=(X_test_ANN, y_test))

# Evaluate ANN Model
accuracy_ANN = model.evaluate(X_test_ANN, y_test)[1]
print("ANN Accuracy:", accuracy_ANN)
